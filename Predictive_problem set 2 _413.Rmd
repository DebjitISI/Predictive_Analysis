---
title: "Problem set 2 (Predictive Ananlysis)"
author: "Pradip(413)"
date: "`r Sys.Date()`"
output: word_document
---
####  1. Problem to demonstrate that the population regression line is fixed, but least square regression line varies

```{r}
set.seed(123)

#Step 1.
X=5:10
Y= 2+(3*X)
plot(X,Y,type = "l", main = "Graph of Regression Line", ylab = "Y=2+3x",col= "blue")

#Step 2.
xi= runif(50,5,10);xi
ei= rnorm(50,0,4);ei
yi= 2+3*xi+ei
#Step 3.
lin_reg= lm(yi~xi)
line= abline(lin_reg, col= "Red")
legend("topleft", legend = c("Population","Sample"), lty = 1, col = c("blue","red"))

#Step 4.
for(j in 1:5)
{
  xi= runif(50,5,10)
  ei= rnorm(50,0,4)
  yi= 2+3*xi+ei
  abline(lm(yi~xi),col = j)
}

```

#### 2. Problem to demonstrate that βˆ0 and βˆ infact minimises RSS
```{r}
set.seed(123)
xi= runif(50,5,10)
mean_centred_xi= xi- mean(xi)
ei= rnorm(50,0,1)
yi= 2+(3*mean_centred_xi)+ei
model= lm(yi~mean_centred_xi);model

beta_0_hat <- coef(model)[1];beta_0_hat
beta_hat <- coef(model)[2];beta_hat


beta0_vals <- c(seq(0,4,.1),2.056189) # Grid for β0
beta_vals <- c(seq(1,5,.1),3.076349)  # Grid for β

# Function to compute the RSS
compute_RSS <- function(beta0, beta, x, y) {
  sum((y - beta0 - beta * x)^2)
}

RSS_matrix = matrix(0, nrow = length(beta0_vals), ncol = length(beta_vals))

for (i in 1:length(beta0_vals)) {
  for (j in 1:length(beta_vals)) {
    RSS_matrix[i,j]= compute_RSS(beta0_vals[i],beta_vals[j],mean_centred_xi,yi)
  }
}
RSS_matrix

which(RSS_matrix==min(RSS_matrix),arr.ind = TRUE)

```

#### 3. Problem to demonstrate that least square estimators are unbiased
```{r warning=FALSE}
set.seed(123)
xi= runif(50,0,1)
ei= rnorm(50,0,1)
yi= 2+(3*xi)+ei
model= lm(yi~xi)
#beta0= coef(model)[1]
#beta= coef(model)[2]

for(i in 1:100){
  xi= runif(50,0,1)
ei= rnorm(50,0,1)
yi= 2+(3*xi)+ei
model[i]= lm(yi~xi)
beta0[i]= coef(model)[1]
beta[i]= coef(model)[2]
}
mean(beta0)
mean(beta)
```

#### 4. Problem to demonstrate the utility of multiple linear regression

```{r}
library(ISLR)
library(stargazer)
attach(Carseats)
data(Carseats)
View(Carseats)
carseats_quant <- Carseats[,-c(7,9,10,11)]

models <- lapply(names(carseats_quant)[-1], function(var) lm(Sales ~ carseats_quant[[var]], data = carseats_quant))

full_model <- lm(Sales ~ ., data = carseats_quant)

stargazer(models, full_model, type = "html",title= "Regression of sales of carseats on different predictors", out = "multiple.html")

# the model here is---
#Sales= b0+b1*CompPrice + b2*Income + b3*Advertising + b4*Population + b5*Price+ b6*Age

#observed F= 76.986
# Reject H0 at 1% level of significance. i.e. at least one predictor is usefl in predicting the response
#Adj R_square= 0.533 i.e the fit is moderate


avg_values <- colMeans(carseats_quant[-1])
predicted_avg <- predict(full_model, newdata = as.data.frame(t(avg_values)), interval = "confidence")

store1_values <- carseats_quant[1, -1]
predicted_store1 <- predict(full_model, newdata = as.data.frame(store1_values), interval = "prediction")

list(confidence_interval = predicted_avg, prediction_interval = predicted_store1)

```

#### 5. Problem to demonstrate the role of qualitative (nominal) predictors in addition to quantitative predictors in multiple linear regression

```{r}
attach(Credit)

lm1= lm(Balance~Gender,data = Credit)
lm2= lm(Balance~Gender+Ethnicity,data = Credit)
lm3= lm(Balance~Gender+Ethnicity+Income,data = Credit)

stargazer(lm1,lm2,lm3,covarite.levels=c("female","Asian","Caucasian"),type= "html", title = "Regression of Balance of credit card on differenct predictors", out= "question5.html")

AIC(lm1)
AIC(lm2)
AIC(lm3)

BIC(lm1)
BIC(lm2)
BIC(lm3)
#comparing AIC,BIC and adjusted R squared model 3 is preffered
```

#### 6. Problem to demonstrate the role of qualitative (ordinal) predictors in addition to quantitative predictors in multiple linear regression
```{r}
library(ggplot2)
attach(diamonds)
View(diamonds)





```



